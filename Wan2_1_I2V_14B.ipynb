{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**PREPARE ENVIRONMENT**"
      ],
      "metadata": {
        "id": "WkDRjQexxNJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You can set **parameters_in_vram** to 10 or less to reduce the VRAM used, especially if you want to generate a video with a resolution greater than 480 by 832 or 832 by 480. The VRAM used depends on the value of **parameters_in_vram** and the resolutions of the input image & output video.\n",
        "- Setting **parameters_in_vram** to 15 with a video resolution of 480 by 832 will result in a generation time of approximately 10 minutes. Lower values of **parameters_in_vram** will result in longer generation times. Higher values can reduce the video generation time, but increase the risk of getting **Out of Memory Error**s."
      ],
      "metadata": {
        "id": "wC_tqstYe52w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "X2XHqPAaJSJl"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "!git clone https://github.com/Isi-dev/DiffSynth-Studio.git\n",
        "%cd DiffSynth-Studio\n",
        "!pip install -e .\n",
        "!pip install \"huggingface_hub[cli]\"\n",
        "!apt-get install -y aria2\n",
        "import os\n",
        "from huggingface_hub import list_repo_files\n",
        "\n",
        "repo_id = \"Isi99999/Wan2.1-I2V-14B-480P\"\n",
        "all_files = list_repo_files(repo_id)\n",
        "base_url = f\"https://huggingface.co/{repo_id}/resolve/main/\"\n",
        "\n",
        "with open(\"file_list.txt\", \"w\") as f:\n",
        "    for file_path in all_files:\n",
        "        full_url = f\"{base_url}{file_path}\"\n",
        "        save_path = f\"models/Wan-AI/Wan2.1-I2V-14B-480P/{file_path}\"\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        f.write(f\"{full_url}\\n out={save_path}\\n\")\n",
        "!aria2c -x 16 -s 16 -i file_list.txt --continue=true --auto-file-renaming=false\n",
        "\n",
        "print(\"✅ All models downloaded successfully!\")\n",
        "\n",
        "import torch\n",
        "from diffsynth import ModelManager, WanVideoPipeline, VideoData, save_video\n",
        "\n",
        "model_manager = ModelManager(device=\"cpu\")\n",
        "model_manager.load_models(\n",
        "    [\"models/Wan-AI/Wan2.1-I2V-14B-480P/models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth\"],\n",
        "    torch_dtype=torch.float16, # Image Encoder is loaded with float16\n",
        ")\n",
        "model_manager.load_models(\n",
        "    [\n",
        "        \"models/Wan-AI/Wan2.1-I2V-14B-480P/diffusion_pytorch_model.safetensors\",\n",
        "        \"models/Wan-AI/Wan2.1-I2V-14B-480P/models_t5_umt5-xxl-enc-bf16.safetensors\",\n",
        "        \"models/Wan-AI/Wan2.1-I2V-14B-480P/Wan2.1_VAE.safetensors\",\n",
        "    ],\n",
        "    torch_dtype=torch.torch.bfloat16, # You can set `torch_dtype=torch.float8_e4m3fn` or `torch_dtype=torch.bfloat16` to disable FP8 quantization.\n",
        ")\n",
        "\n",
        "pipe = WanVideoPipeline.from_model_manager(model_manager, torch_dtype=torch.bfloat16, device=\"cuda\")\n",
        "parameters_in_vram = 14 # @param {\"type\":\"number\"}\n",
        "pipe.enable_vram_management(num_persistent_param_in_dit=parameters_in_vram*10**9) # You can set `num_persistent_param_in_dit` to a small number to reduce VRAM required.\n",
        "print(\"✅ All models loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN TO UPLOAD IMAGE**"
      ],
      "metadata": {
        "id": "v6g0SqdGaKAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "image = Image.open(image_path)\n",
        "\n",
        "print(\"✅Image loaded successfully:\", image.size)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_jBdEI7BS7cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN IMAGE TO VIDEO**"
      ],
      "metadata": {
        "id": "S3zCgOnBaO4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "prompt = \"The lady smiles and waves at the camera.\" # @param {type:\"string\"}\n",
        "sample_steps = 30 # @param {\"type\":\"number\"}\n",
        "Instruction = \"choose from '720*1280', '1280*720', '480*832', '832*480', '1024*1024 for output video's width & height.\" # @param {\"type\":\"string\"}\n",
        "width = 480 # @param {\"type\":\"number\"}\n",
        "height = 832 # @param {\"type\":\"number\"}\n",
        "num_frames = 81 # @param {\"type\":\"number\"}\n",
        "seed = 1 # @param {\"type\":\"number\"}\n",
        "\n",
        "# Generate video from text prompt and Image\n",
        "video = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=\"色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走\",\n",
        "    input_image=image,\n",
        "    height = height,\n",
        "    width = width,\n",
        "    num_frames=num_frames,\n",
        "    num_inference_steps=sample_steps,\n",
        "    seed=seed, tiled=True\n",
        ")\n",
        "\n",
        "# # Save the generated video\n",
        "save_video(video, \"video.mp4\", fps=15, quality=5)\n",
        "\n",
        "from IPython.display import display as displayVid, Video as outVid\n",
        "import os\n",
        "\n",
        "# Function to display video\n",
        "def show_video(video_path):\n",
        "    if os.path.exists(video_path):\n",
        "        displayVid(outVid(video_path, embed=True))\n",
        "    else:\n",
        "        print(f\"Error: {video_path} not found!\")\n",
        "\n",
        "# Show the video\n",
        "show_video(\"video.mp4\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6CyP7yjoMVn9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}